{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Regression Hypothesis testing with Vector Spaces\n",
    "\n",
    "```\n",
    "Author:\n",
    "Zach Wolpe\n",
    "zachcolinwolpe@gmail.com\n",
    "zach.world\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Regression Calculations\n",
    "\n",
    "Clean data and compute the standard regression values of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent/independent variables and add intercept\n",
    "X = data.data\n",
    "X = sm.add_constant(X)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAL dataset\n",
    "df = pd.read_csv('RAL_data.txt')\n",
    "y = df.iloc[:,0]\n",
    "X = df.iloc[:, 1:]\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Hat matrix / Projection matrix\n",
    "inv = np.linalg.inv\n",
    "XPX = np.dot(X.T,X)\n",
    "invXPX = inv(XPX)\n",
    "H = np.dot(np.dot(X, invXPX),X.T)\n",
    "\n",
    "# sums\n",
    "n = X.shape[0] \n",
    "p = X.shape[1]\n",
    "I = np.identity(n)\n",
    "sumY = np.sum(np.array(y))\n",
    "sumX = np.sum(X)\n",
    "XY = np.dot(X.T, y)\n",
    "XX = np.dot(X.T, X)\n",
    "yy = np.dot(y.T, y)\n",
    "\n",
    "########################################## Estimates ##########################################\n",
    "\n",
    "# betas\n",
    "b = np.dot(inv(XX), XY)\n",
    "\n",
    "# Y_hat\n",
    "yhat = np.dot(H,y)\n",
    "yhat = np.dot(X,b)\n",
    "\n",
    "# error\n",
    "e = y - yhat\n",
    "e = np.dot((I-H),y)\n",
    "\n",
    "####################################### Sum of Squares #######################################\n",
    "\n",
    "# sse\n",
    "sse = np.dot(e.T, e)\n",
    "\n",
    "# sstou\n",
    "sstou = np.dot(y.T, y)\n",
    "\n",
    "# ss1 \n",
    "ss1 = 1/n*(sumY**2)\n",
    "\n",
    "# ssx\n",
    "ssx = np.dot(y.T, yhat)\n",
    "ssx = np.dot(np.dot(b.T, X.T),y)\n",
    "\n",
    "# ssr \n",
    "ssr = ssx - ss1\n",
    "\n",
    "# ssto \n",
    "ssto = sstou - ss1\n",
    "\n",
    "####################################### Mean Squares #######################################\n",
    "\n",
    "# MSE \n",
    "mse = sse/(n-p)\n",
    "\n",
    "# MSR\n",
    "msr = ssr/(p-1)\n",
    "\n",
    "########################################### ANOVA ###########################################\n",
    "\n",
    "\n",
    "# F statistic\n",
    "F = msr/mse\n",
    "\n",
    "# F critical value\n",
    "F_crit = st.f.ppf(q=(1-0.05), dfn=(p-1), dfd=(n-p))\n",
    "\n",
    "# p-value\n",
    "p_value = 1 - st.f.cdf(F, p-1, n-p)\n",
    "\n",
    "\n",
    "######################################## Correlation ########################################\n",
    "\n",
    "\n",
    "\n",
    "# R squared (coefficient of multiple determination)\n",
    "R2 = ssr/ssto\n",
    "\n",
    "# adjusted R squared\n",
    "R2_adjusted = 1 - (sse/(n-p))/(ssto/(n-1))\n",
    "\n",
    "# coefficient of multiple correlation\n",
    "r = np.sqrt(R2)\n",
    "\n",
    "\n",
    "######################################### Variances #########################################\n",
    "\n",
    "# var{beta} (covariance matrix of Beta's)\n",
    "covb = mse*invXPX\n",
    "\n",
    "# var{Yhat}\n",
    "varYh = mse*H\n",
    "\n",
    "# var{e}\n",
    "varE = mse*(I-H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Beta Confidence intervals\n",
    "\n",
    "Allows us to test any parameter estimates confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betas_CI(X, y, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Allows us to test any parameter estimates confidence interval. \n",
    "    T distribution Confidence Intervals\n",
    "    \n",
    "    X:         matrix of X independent variables\n",
    "    y:         target (response) variable\n",
    "    alpha:     level of significance\n",
    "    center:    number to center CI around / add later\n",
    "    \"\"\"\n",
    "    \n",
    "    n = y.shape[0]\n",
    "    p = X.shape[1]\n",
    "    XPX = np.dot(X.T,X)\n",
    "    sstou = np.dot(y.T, y)\n",
    "    np.linalg.inv(XPX)\n",
    "    b = np.dot(invXPX, np.dot(X.T, y))\n",
    "    ssx = np.dot(b.T, np.dot(X.T, y))\n",
    "    sse = sstou - ssx\n",
    "    mse = sse/(n-p)\n",
    "    \n",
    "    covb = mse*invXPX\n",
    "    \n",
    "    \n",
    "    intervals = []\n",
    "    for i in range(X.shape[1]):\n",
    "        \n",
    "        std = np.sqrt(covb[i,i])\n",
    "        \n",
    "\n",
    "        # interval\n",
    "        add = ((b[i] - st.t.ppf(1-(alpha/2),df=n-p)*std), (b[i] + st.t.ppf(1-(alpha/2),df=n-p)*std))\n",
    "        intervals.append(add)\n",
    "        \n",
    "    return np.array(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confidence intervals for betas (alpha=0.05): \n",
      "\n",
      "[[121.91172735 195.07077598]\n",
      " [ -1.57509339  -0.7081303 ]\n",
      " [ -1.43483133   0.55082281]\n",
      " [-27.79785874   0.85753235]]\n"
     ]
    }
   ],
   "source": [
    "CIs = betas_CI(X, y, alpha=0.05)\n",
    "print('')\n",
    "print('confidence intervals for betas (alpha=0.05): ')\n",
    "print('')\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial F test\n",
    "\n",
    "Any regression hypothesis can be specified in terms of Full and Reduced models, wherein the reduced model assumes $H_0$ to be true. \n",
    "\n",
    "Most commonly used to test Extra sum of squares in the General Linear Approach.\n",
    "\n",
    "## Extra Sum of Squares\n",
    "\n",
    "$$SSR(X_i|X_j,X_k) = SSR(X_i,X_j,X_k) - SSR(X_j,X_k)$$\n",
    "\n",
    "To test the partial effect of adding an independent variable, given the current model specification, we can assess the extra sum of squares - which simply calculates the increase in regression SS or decrease in error SS if additional explanatory variables are added to the model.\n",
    "\n",
    "### Coefficient of Partial Determination\n",
    "$$R^2_{1|2} = \\frac{SSR(X1 | x2)}{SSE(X2)}$$\n",
    "\n",
    "Measures the proportion reduction of  $SSE(X2)$ (in this example) when $X1$ is added to the model. Calculates the marginal reduction in variance of $Y$ when $X1$ is added to a model containing $X2$\n",
    "\n",
    "\n",
    "### Degrees of Freedom\n",
    "$df_i$: An Extra SS has degrees of freedom $=$ no. additional $X$ variables\n",
    "\n",
    "## Partial F-test\n",
    "F-test can be used to test if the marginal effects are measurable. The F test is given in terms of the _Full Model_ & _Reduced Model_:\n",
    "\n",
    "$$F^* = \\frac{SSR(X_i|X_j, X_k)/df_i}{SSE(X_j, X_k, X_i)/(n-p)} \\sim F(df_i, n-p)$$\n",
    "\n",
    "Specify research questions such that:\n",
    "\n",
    "$$H_0: Reduced Model$$\n",
    "$$H_a: Full Model$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_F_test(y, reduced, full, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Derive the F statistics for an extra sum of squares\n",
    "\n",
    "    y:     vector, target variable (n x 1)\n",
    "    \n",
    "    full: all X var in the full model\n",
    "    reduced: all X vars in the reduced model\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert to dataframe\n",
    "    reduced = pd.DataFrame(reduced)\n",
    "    full = pd.DataFrame(full)\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    sstou = np.dot(y.T, y)\n",
    "    \n",
    "    # reduced model calculations\n",
    "    if (reduced.shape[1] > 1):\n",
    "        inv_xpx_r = np.linalg.inv(np.dot(reduced.T, reduced))\n",
    "    else:\n",
    "        inv_xpx_r = np.reciprocal(np.dot(reduced.T, reduced))\n",
    "        \n",
    "    XY_r = np.dot(reduced.T, y)\n",
    "    ssx_r = np.dot(np.dot(np.dot(y.T, reduced), inv_xpx_r), XY_r)\n",
    "    sse_r = sstou - ssx_r\n",
    "    df_r = reduced.shape[0] - reduced.shape[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # full model calculations\n",
    "    if (reduced.shape[1] > 1):\n",
    "        inv_xpx_f = np.linalg.inv(np.dot(full.T, full))\n",
    "    else:\n",
    "        inv_xpx_f = np.reciprocal(np.dot(full.T, full))\n",
    "        \n",
    "        \n",
    "    XY_f = np.dot(full.T, y)\n",
    "    ssx_f = np.dot(np.dot(np.dot(y.T, full), inv_xpx_f), XY_f)\n",
    "    sse_f = sstou - ssx_f\n",
    "    df_f = full.shape[0] - full.shape[1]\n",
    "    \n",
    "    mseF = sse_f/df_f\n",
    "    \n",
    "    # extra SS\n",
    "    extra_SS = ssx_f - ssx_r\n",
    "    \n",
    "    # F statistic\n",
    "    F = ((sse_r-sse_f)/(df_r - df_f))/mseF\n",
    "    \n",
    "    \n",
    "    # critical value\n",
    "    F_crit = st.f.ppf(1-alpha, df_r, df_f)\n",
    "    \n",
    "    # p value\n",
    "    p_value = st.f.pdf(F, df_r, df_f)\n",
    "    \n",
    "    # Partial R Squared\n",
    "    partial_R2 = extra_SS/sse_r\n",
    "    \n",
    "    \n",
    "    results = {\n",
    "        'F statistic': F,\n",
    "        'extra SS': extra_SS,\n",
    "        'critcal value': F_crit,\n",
    "        'p value': p_value,\n",
    "        'partial R2': partial_R2,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F statistic': array([[36.31690673]]),\n",
       " 'extra SS': array([[3896.04414241]]),\n",
       " 'critcal value': 1.6572460294627507,\n",
       " 'p value': array([[2.46261102e-23]]),\n",
       " 'partial R2': array([[0.45787094]])}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_model = pd.concat([X.iloc[:,0], X.iloc[:,2]], axis=1)\n",
    "full_model = X.iloc[:,0:3]\n",
    "res = partial_F_test(y, reduced_model, full_model, alpha=0.05)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothysis testing: Matrix notation\n",
    "\n",
    "Analogous to the above F test, however specified in Matrix notation.\n",
    "\n",
    "Test any Hypothesis specified in the form:\n",
    "$$H_0: LB = c$$\n",
    "$$H_0: LB \\neq c$$\n",
    "\n",
    "By computing the $F^*$ statistic:\n",
    "\n",
    "$$F^* = \\frac{(LB - c)` (L(X`X)^{-1}L`)^{-1}(LB - c) /r}{MSE} \\sim F(1-a, r, n-p)$$\n",
    "\n",
    "\n",
    "let $Q = (LB - c)` (L(X`X)^{-1}L`)^{-1}(LB - c)$\n",
    "\n",
    "\n",
    "## Degrees of freedom\n",
    "#### numerator\n",
    "$r$: no. linear independent functions in $L$\n",
    "\n",
    "#### denominator\n",
    "$n-p$: sse df from the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LB_F_statistics(L, X, y, c, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate the definitive statistics for an\n",
    "    H0: LB = c\n",
    "    hypothesis test.\n",
    "    \n",
    "    Parameters:\n",
    "    L & c: (vector/matrix) hypothesis parameters\n",
    "    X: (vector/matrix) independent variables\n",
    "    y: (vector) target variable\n",
    "    alpha: level of significance\n",
    "    \"\"\"\n",
    "    # calculate Beta's\n",
    "    XX = np.dot(X.T, X)\n",
    "    XY = np.dot(X.T, y)\n",
    "    invXX = np.linalg.inv(XX)\n",
    "    b = pd.DataFrame(np.dot(invXX, XY))\n",
    "    \n",
    "    # calculate Q\n",
    "    r = L.shape[0]\n",
    "    Lb = np.dot(L, b)\n",
    "    if np.array([np.dot(np.dot(L,invXX), L.T)]).shape[0] > 2:\n",
    "        Q_center = np.linalg.inv(np.dot(L, np.dot(invXX, L.T)))\n",
    "    else:\n",
    "        Q_center = np.reciprocal(np.dot(L, np.dot(invXX, L.T)))\n",
    "    Q = np.dot(np.dot((Lb-c).T, Q_center), (Lb-c))\n",
    "    \n",
    "    \n",
    "    # calculate MSE\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    sse = np.dot(y.T,y) - np.dot(np.dot(b.T, X.T), y)\n",
    "    mse = sse/(n-p)\n",
    "    \n",
    "    # calculate F statistic\n",
    "    F = (Q/r)/mse\n",
    "    \n",
    "    # critical value\n",
    "    F_crit = st.f.ppf(1-alpha, r, (n-p))\n",
    "    \n",
    "    # p value \n",
    "    p_value = st.f.pdf(F, r, (n-p))\n",
    "    \n",
    "    results = {\n",
    "        'F statistic': F,\n",
    "        'F critical': F_crit,\n",
    "        'p value': p_value\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F statistic': array([1.22887489]),\n",
       " 'F critical': 2.594263371345763,\n",
       " 'p value': array([0.40385809])}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.array([0,1,1,1])\n",
    "c = np.array([0])\n",
    "r = LB_F_statistics(L, X, y, c)\n",
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
